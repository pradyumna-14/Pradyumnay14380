{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "51430221-f91b-4524-a878-032a91dbf948",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (16000, 16)\n",
      "Test set shape: (4000, 16)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>letter</th>\n",
       "      <th>xbox</th>\n",
       "      <th>ybox</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>onpix</th>\n",
       "      <th>xbar</th>\n",
       "      <th>ybar</th>\n",
       "      <th>x2bar</th>\n",
       "      <th>y2bar</th>\n",
       "      <th>xybar</th>\n",
       "      <th>x2ybar</th>\n",
       "      <th>xy2bar</th>\n",
       "      <th>xedge</th>\n",
       "      <th>xedgey</th>\n",
       "      <th>yedge</th>\n",
       "      <th>yedgex</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>T</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I</td>\n",
       "      <td>5</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>N</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>D</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>C</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>T</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>S</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
       "0          T     2     8      3       5      1     8    13      0      6   \n",
       "1          I     5    12      3       7      2    10     5      5      4   \n",
       "2          D     4    11      6       8      6    10     6      2      6   \n",
       "3          N     7    11      6       6      3     5     9      4      6   \n",
       "4          G     2     1      3       1      1     8     6      6      6   \n",
       "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
       "19995      D     2     2      3       3      2     7     7      7      6   \n",
       "19996      C     7    10      8       8      4     4     8      6      9   \n",
       "19997      T     6     9      6       7      5     6    11      3      7   \n",
       "19998      S     2     3      4       2      1     8     7      2      6   \n",
       "19999      A     4     9      6       6      2     9     5      3      1   \n",
       "\n",
       "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
       "0          6      10       8      0       8      0       8  \n",
       "1         13       3       9      2       8      4      10  \n",
       "2         10       3       7      3       7      3       9  \n",
       "3          4       4      10      6      10      2       8  \n",
       "4          6       5       9      1       7      5      10  \n",
       "...      ...     ...     ...    ...     ...    ...     ...  \n",
       "19995      6       6       4      2       8      3       7  \n",
       "19996     12       9      13      2       9      3       7  \n",
       "19997     11       9       5      2      12      2       4  \n",
       "19998     10       6       8      1       9      5       8  \n",
       "19999      8       1       8      2       7      2       8  \n",
       "\n",
       "[20000 rows x 17 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\91808\\Downloads\\Alphabets_data.csv\")\n",
    "\n",
    "# Step 1: Separate features and target\n",
    "X = df.drop(\"letter\", axis=1)\n",
    "y = df[\"letter\"]\n",
    "\n",
    "# Step 2: Encode the target labels (A-Z -> 0-25)\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Step 3: Normalize the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Step 4: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    ")\n",
    "\n",
    "# Shapes of final datasets\n",
    "print(\"Training set shape:\", X_train.shape)\n",
    "print(\"Test set shape:\", X_test.shape)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4656e493-cb13-4ef5-afcd-ce91114a8586",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting tensorflow\n",
      "  Using cached tensorflow-2.19.0-cp312-cp312-win_amd64.whl.metadata (4.1 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Using cached astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Using cached flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Using cached gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow)\n",
      "  Using cached google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Using cached libclang-18.1.1-py2.py3-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow)\n",
      "  Using cached opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.16.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Using cached termcolor-3.0.1-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.14.1)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Using cached grpcio-1.71.0-cp312-cp312-win_amd64.whl.metadata (4.0 kB)\n",
      "Collecting tensorboard~=2.19.0 (from tensorflow)\n",
      "  Using cached tensorboard-2.19.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.5.0 (from tensorflow)\n",
      "  Using cached keras-3.9.2-py3-none-any.whl.metadata (6.1 kB)\n",
      "Requirement already satisfied: numpy<2.2.0,>=1.26.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow) (3.11.0)\n",
      "Collecting ml-dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Using cached ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.5.0->tensorflow) (13.7.1)\n",
      "Collecting namex (from keras>=3.5.0->tensorflow)\n",
      "  Downloading namex-0.0.9-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.5.0->tensorflow)\n",
      "  Using cached optree-0.15.0-cp312-cp312-win_amd64.whl.metadata (49 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.4.1)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.19.0->tensorflow)\n",
      "  Using cached tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "Downloading tensorflow-2.19.0-cp312-cp312-win_amd64.whl (376.0 MB)\n",
      "   ---------------------------------------- 0.0/376.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.6/376.0 MB 10.5 MB/s eta 0:00:36\n",
      "   ---------------------------------------- 3.1/376.0 MB 9.2 MB/s eta 0:00:41\n",
      "    --------------------------------------- 5.2/376.0 MB 9.1 MB/s eta 0:00:41\n",
      "    --------------------------------------- 7.1/376.0 MB 9.3 MB/s eta 0:00:40\n",
      "    --------------------------------------- 7.6/376.0 MB 9.4 MB/s eta 0:00:40\n",
      "   - -------------------------------------- 10.0/376.0 MB 8.4 MB/s eta 0:00:44\n",
      "   - -------------------------------------- 11.5/376.0 MB 8.6 MB/s eta 0:00:43\n",
      "   - -------------------------------------- 13.4/376.0 MB 8.6 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 15.5/376.0 MB 8.8 MB/s eta 0:00:42\n",
      "   - -------------------------------------- 17.3/376.0 MB 8.6 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 19.4/376.0 MB 8.9 MB/s eta 0:00:41\n",
      "   -- ------------------------------------- 20.4/376.0 MB 8.7 MB/s eta 0:00:42\n",
      "   -- ------------------------------------- 23.6/376.0 MB 8.9 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 25.7/376.0 MB 8.9 MB/s eta 0:00:40\n",
      "   -- ------------------------------------- 27.5/376.0 MB 8.9 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 29.4/376.0 MB 9.0 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 31.2/376.0 MB 9.0 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 33.0/376.0 MB 9.0 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 35.1/376.0 MB 9.0 MB/s eta 0:00:39\n",
      "   --- ------------------------------------ 37.2/376.0 MB 9.0 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 38.8/376.0 MB 9.0 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 40.4/376.0 MB 8.9 MB/s eta 0:00:38\n",
      "   ---- ----------------------------------- 42.7/376.0 MB 9.0 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 44.8/376.0 MB 9.0 MB/s eta 0:00:37\n",
      "   ---- ----------------------------------- 46.7/376.0 MB 9.0 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 48.5/376.0 MB 9.0 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 50.1/376.0 MB 9.0 MB/s eta 0:00:37\n",
      "   ----- ---------------------------------- 52.2/376.0 MB 9.0 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 53.7/376.0 MB 9.0 MB/s eta 0:00:36\n",
      "   ----- ---------------------------------- 56.1/376.0 MB 9.0 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 57.4/376.0 MB 9.1 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 59.2/376.0 MB 9.0 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 61.3/376.0 MB 9.0 MB/s eta 0:00:36\n",
      "   ------ --------------------------------- 62.7/376.0 MB 9.0 MB/s eta 0:00:35\n",
      "   ------ --------------------------------- 65.0/376.0 MB 8.9 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 67.1/376.0 MB 9.0 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 68.9/376.0 MB 9.0 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 70.8/376.0 MB 9.0 MB/s eta 0:00:35\n",
      "   ------- -------------------------------- 72.9/376.0 MB 9.0 MB/s eta 0:00:34\n",
      "   ------- -------------------------------- 75.0/376.0 MB 9.0 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 77.1/376.0 MB 9.0 MB/s eta 0:00:34\n",
      "   -------- ------------------------------- 78.9/376.0 MB 9.0 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 80.7/376.0 MB 9.0 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 82.6/376.0 MB 9.0 MB/s eta 0:00:33\n",
      "   -------- ------------------------------- 83.9/376.0 MB 9.0 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 86.2/376.0 MB 9.0 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 88.1/376.0 MB 9.0 MB/s eta 0:00:33\n",
      "   --------- ------------------------------ 90.2/376.0 MB 9.0 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 92.0/376.0 MB 9.0 MB/s eta 0:00:32\n",
      "   --------- ------------------------------ 93.8/376.0 MB 9.0 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 95.7/376.0 MB 9.0 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 97.5/376.0 MB 9.0 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 98.8/376.0 MB 8.9 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 100.1/376.0 MB 8.9 MB/s eta 0:00:32\n",
      "   ---------- ----------------------------- 102.8/376.0 MB 8.9 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 104.1/376.0 MB 8.9 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 105.9/376.0 MB 8.9 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 108.0/376.0 MB 8.9 MB/s eta 0:00:31\n",
      "   ----------- ---------------------------- 109.8/376.0 MB 8.9 MB/s eta 0:00:30\n",
      "   ----------- ---------------------------- 111.1/376.0 MB 8.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 113.0/376.0 MB 8.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 114.8/376.0 MB 8.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 116.4/376.0 MB 8.9 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 117.4/376.0 MB 8.8 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 119.0/376.0 MB 8.8 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 120.8/376.0 MB 8.8 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 121.6/376.0 MB 8.7 MB/s eta 0:00:30\n",
      "   ------------ --------------------------- 122.2/376.0 MB 8.6 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 122.4/376.0 MB 8.6 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 122.7/376.0 MB 8.5 MB/s eta 0:00:30\n",
      "   ------------- -------------------------- 123.2/376.0 MB 8.4 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 123.5/376.0 MB 8.3 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 123.7/376.0 MB 8.2 MB/s eta 0:00:31\n",
      "   ------------- -------------------------- 124.0/376.0 MB 8.1 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 124.5/376.0 MB 8.0 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 125.0/376.0 MB 7.9 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 125.8/376.0 MB 7.9 MB/s eta 0:00:32\n",
      "   ------------- -------------------------- 126.4/376.0 MB 7.8 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 126.9/376.0 MB 7.7 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 127.7/376.0 MB 7.7 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 128.2/376.0 MB 7.6 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 128.5/376.0 MB 7.6 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 128.7/376.0 MB 7.5 MB/s eta 0:00:33\n",
      "   ------------- -------------------------- 129.0/376.0 MB 7.4 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 129.2/376.0 MB 7.4 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 129.5/376.0 MB 7.3 MB/s eta 0:00:34\n",
      "   ------------- -------------------------- 130.0/376.0 MB 7.2 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 130.0/376.0 MB 7.2 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 130.3/376.0 MB 7.1 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 130.5/376.0 MB 7.0 MB/s eta 0:00:35\n",
      "   ------------- -------------------------- 130.8/376.0 MB 7.0 MB/s eta 0:00:36\n",
      "   ------------- -------------------------- 131.1/376.0 MB 6.9 MB/s eta 0:00:36\n",
      "   -------------- ------------------------- 131.6/376.0 MB 6.8 MB/s eta 0:00:36\n",
      "   -------------- ------------------------- 131.9/376.0 MB 6.8 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 132.1/376.0 MB 6.7 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 132.4/376.0 MB 6.7 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 132.9/376.0 MB 6.6 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 133.4/376.0 MB 6.6 MB/s eta 0:00:37\n",
      "   -------------- ------------------------- 134.0/376.0 MB 6.5 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 134.2/376.0 MB 6.5 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 134.5/376.0 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 135.0/376.0 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 135.3/376.0 MB 6.4 MB/s eta 0:00:38\n",
      "   -------------- ------------------------- 135.5/376.0 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 135.5/376.0 MB 6.3 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 136.6/376.0 MB 6.2 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 137.6/376.0 MB 6.2 MB/s eta 0:00:39\n",
      "   -------------- ------------------------- 139.2/376.0 MB 6.2 MB/s eta 0:00:39\n",
      "   --------------- ------------------------ 141.3/376.0 MB 6.2 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 143.1/376.0 MB 6.3 MB/s eta 0:00:38\n",
      "   --------------- ------------------------ 145.2/376.0 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 147.3/376.0 MB 6.3 MB/s eta 0:00:37\n",
      "   --------------- ------------------------ 149.2/376.0 MB 6.3 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 151.0/376.0 MB 6.4 MB/s eta 0:00:36\n",
      "   ---------------- ----------------------- 153.1/376.0 MB 6.4 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 154.9/376.0 MB 6.4 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 156.8/376.0 MB 6.4 MB/s eta 0:00:35\n",
      "   ---------------- ----------------------- 158.6/376.0 MB 6.5 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 160.7/376.0 MB 6.5 MB/s eta 0:00:34\n",
      "   ----------------- ---------------------- 162.8/376.0 MB 6.5 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 164.6/376.0 MB 6.5 MB/s eta 0:00:33\n",
      "   ----------------- ---------------------- 166.7/376.0 MB 6.6 MB/s eta 0:00:32\n",
      "   ----------------- ---------------------- 168.3/376.0 MB 6.6 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 170.1/376.0 MB 6.6 MB/s eta 0:00:32\n",
      "   ------------------ --------------------- 172.2/376.0 MB 6.6 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 174.1/376.0 MB 6.6 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 175.9/376.0 MB 6.7 MB/s eta 0:00:31\n",
      "   ------------------ --------------------- 177.7/376.0 MB 6.7 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 179.8/376.0 MB 6.7 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 181.4/376.0 MB 6.7 MB/s eta 0:00:30\n",
      "   ------------------- -------------------- 183.5/376.0 MB 6.7 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 185.3/376.0 MB 6.7 MB/s eta 0:00:29\n",
      "   ------------------- -------------------- 187.2/376.0 MB 6.8 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 189.0/376.0 MB 6.8 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 190.8/376.0 MB 6.8 MB/s eta 0:00:28\n",
      "   -------------------- ------------------- 192.9/376.0 MB 6.8 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 194.8/376.0 MB 6.8 MB/s eta 0:00:27\n",
      "   -------------------- ------------------- 196.6/376.0 MB 6.8 MB/s eta 0:00:27\n",
      "   --------------------- ------------------ 198.7/376.0 MB 6.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 200.8/376.0 MB 6.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 202.1/376.0 MB 6.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 203.7/376.0 MB 6.9 MB/s eta 0:00:26\n",
      "   --------------------- ------------------ 204.7/376.0 MB 6.9 MB/s eta 0:00:25\n",
      "   --------------------- ------------------ 205.8/376.0 MB 6.9 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 207.1/376.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 208.1/376.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 209.5/376.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 211.0/376.0 MB 6.8 MB/s eta 0:00:25\n",
      "   ---------------------- ----------------- 212.3/376.0 MB 6.8 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 214.2/376.0 MB 6.8 MB/s eta 0:00:24\n",
      "   ---------------------- ----------------- 215.5/376.0 MB 6.8 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 217.1/376.0 MB 6.8 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 218.4/376.0 MB 6.7 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 219.9/376.0 MB 6.7 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 221.2/376.0 MB 6.7 MB/s eta 0:00:24\n",
      "   ----------------------- ---------------- 222.6/376.0 MB 6.7 MB/s eta 0:00:23\n",
      "   ----------------------- ---------------- 224.1/376.0 MB 6.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 225.7/376.0 MB 6.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 227.3/376.0 MB 6.6 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 229.1/376.0 MB 6.7 MB/s eta 0:00:23\n",
      "   ------------------------ --------------- 230.9/376.0 MB 6.6 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 232.8/376.0 MB 6.6 MB/s eta 0:00:22\n",
      "   ------------------------ --------------- 234.6/376.0 MB 6.6 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 236.5/376.0 MB 6.6 MB/s eta 0:00:22\n",
      "   ------------------------- -------------- 238.3/376.0 MB 6.6 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 240.4/376.0 MB 6.6 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 242.2/376.0 MB 6.6 MB/s eta 0:00:21\n",
      "   ------------------------- -------------- 244.1/376.0 MB 6.6 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 245.9/376.0 MB 6.6 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 248.0/376.0 MB 6.6 MB/s eta 0:00:20\n",
      "   -------------------------- ------------- 249.8/376.0 MB 6.6 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 251.9/376.0 MB 6.6 MB/s eta 0:00:19\n",
      "   -------------------------- ------------- 253.8/376.0 MB 6.6 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 255.6/376.0 MB 6.6 MB/s eta 0:00:19\n",
      "   --------------------------- ------------ 257.2/376.0 MB 6.7 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 259.0/376.0 MB 6.7 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 261.1/376.0 MB 6.6 MB/s eta 0:00:18\n",
      "   --------------------------- ------------ 262.9/376.0 MB 6.7 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 265.0/376.0 MB 6.6 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 266.9/376.0 MB 6.6 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 268.7/376.0 MB 6.6 MB/s eta 0:00:17\n",
      "   ---------------------------- ----------- 270.8/376.0 MB 6.6 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 272.6/376.0 MB 6.6 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 274.5/376.0 MB 6.7 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 276.3/376.0 MB 6.6 MB/s eta 0:00:16\n",
      "   ----------------------------- ---------- 278.4/376.0 MB 6.6 MB/s eta 0:00:15\n",
      "   ----------------------------- ---------- 280.2/376.0 MB 6.7 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 282.1/376.0 MB 6.7 MB/s eta 0:00:15\n",
      "   ------------------------------ --------- 284.2/376.0 MB 6.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 286.0/376.0 MB 6.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 288.1/376.0 MB 6.7 MB/s eta 0:00:14\n",
      "   ------------------------------ --------- 289.9/376.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 291.8/376.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 293.6/376.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 295.7/376.0 MB 6.7 MB/s eta 0:00:13\n",
      "   ------------------------------- -------- 297.5/376.0 MB 6.7 MB/s eta 0:00:12\n",
      "   ------------------------------- -------- 299.4/376.0 MB 6.7 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 301.5/376.0 MB 6.7 MB/s eta 0:00:12\n",
      "   -------------------------------- ------- 303.3/376.0 MB 6.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 305.4/376.0 MB 6.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 307.0/376.0 MB 6.7 MB/s eta 0:00:11\n",
      "   -------------------------------- ------- 309.1/376.0 MB 6.7 MB/s eta 0:00:11\n",
      "   --------------------------------- ------ 311.2/376.0 MB 6.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 313.0/376.0 MB 6.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 314.8/376.0 MB 6.7 MB/s eta 0:00:10\n",
      "   --------------------------------- ------ 316.9/376.0 MB 6.7 MB/s eta 0:00:09\n",
      "   --------------------------------- ------ 318.8/376.0 MB 6.7 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 320.9/376.0 MB 6.8 MB/s eta 0:00:09\n",
      "   ---------------------------------- ----- 322.7/376.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 324.8/376.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 326.6/376.0 MB 6.8 MB/s eta 0:00:08\n",
      "   ---------------------------------- ----- 328.5/376.0 MB 6.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 330.3/376.0 MB 6.9 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 332.1/376.0 MB 7.0 MB/s eta 0:00:07\n",
      "   ----------------------------------- ---- 334.0/376.0 MB 7.0 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 336.1/376.0 MB 7.1 MB/s eta 0:00:06\n",
      "   ----------------------------------- ---- 337.9/376.0 MB 7.1 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 339.7/376.0 MB 7.2 MB/s eta 0:00:06\n",
      "   ------------------------------------ --- 341.6/376.0 MB 7.2 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 343.7/376.0 MB 7.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 345.2/376.0 MB 7.3 MB/s eta 0:00:05\n",
      "   ------------------------------------ --- 346.6/376.0 MB 7.3 MB/s eta 0:00:05\n",
      "   ------------------------------------- -- 349.2/376.0 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 351.0/376.0 MB 7.4 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 353.1/376.0 MB 7.5 MB/s eta 0:00:04\n",
      "   ------------------------------------- -- 354.7/376.0 MB 7.5 MB/s eta 0:00:03\n",
      "   ------------------------------------- -- 356.8/376.0 MB 7.6 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 358.6/376.0 MB 7.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 360.4/376.0 MB 7.7 MB/s eta 0:00:03\n",
      "   -------------------------------------- - 362.3/376.0 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 364.4/376.0 MB 7.8 MB/s eta 0:00:02\n",
      "   -------------------------------------- - 366.2/376.0 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  367.8/376.0 MB 7.9 MB/s eta 0:00:02\n",
      "   ---------------------------------------  368.8/376.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  371.2/376.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  373.0/376.0 MB 8.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  374.9/376.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  375.9/376.0 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 376.0/376.0 MB 8.1 MB/s eta 0:00:00\n",
      "Downloading absl_py-2.2.2-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading grpcio-1.71.0-cp312-cp312-win_amd64.whl (4.3 MB)\n",
      "   ---------------------------------------- 0.0/4.3 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.8/4.3 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 3.9/4.3 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 4.3/4.3 MB 8.9 MB/s eta 0:00:00\n",
      "Downloading keras-3.9.2-py3-none-any.whl (1.3 MB)\n",
      "   ---------------------------------------- 0.0/1.3 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.3/1.3 MB 9.8 MB/s eta 0:00:00\n",
      "Downloading libclang-18.1.1-py2.py3-none-win_amd64.whl (26.4 MB)\n",
      "   ---------------------------------------- 0.0/26.4 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 1.8/26.4 MB 9.1 MB/s eta 0:00:03\n",
      "   ----- ---------------------------------- 3.7/26.4 MB 9.1 MB/s eta 0:00:03\n",
      "   -------- ------------------------------- 5.5/26.4 MB 9.1 MB/s eta 0:00:03\n",
      "   ----------- ---------------------------- 7.6/26.4 MB 9.0 MB/s eta 0:00:03\n",
      "   -------------- ------------------------- 9.4/26.4 MB 9.2 MB/s eta 0:00:02\n",
      "   ----------------- ---------------------- 11.5/26.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 13.1/26.4 MB 9.1 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 15.2/26.4 MB 9.1 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 17.3/26.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 19.1/26.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ------------------------------- -------- 20.7/26.4 MB 9.1 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 22.8/26.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 24.6/26.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------  26.2/26.4 MB 9.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 26.4/26.4 MB 9.0 MB/s eta 0:00:00\n",
      "Downloading ml_dtypes-0.5.1-cp312-cp312-win_amd64.whl (210 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorboard-2.19.0-py3-none-any.whl (5.5 MB)\n",
      "   ---------------------------------------- 0.0/5.5 MB ? eta -:--:--\n",
      "   --------------- ------------------------ 2.1/5.5 MB 9.8 MB/s eta 0:00:01\n",
      "   ---------------------------- ----------- 3.9/5.5 MB 9.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 5.5/5.5 MB 8.8 MB/s eta 0:00:00\n",
      "Downloading termcolor-3.0.1-py3-none-any.whl (7.2 kB)\n",
      "Downloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading namex-0.0.9-py3-none-any.whl (5.8 kB)\n",
      "Downloading optree-0.15.0-cp312-cp312-win_amd64.whl (307 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, termcolor, tensorboard-data-server, optree, opt-einsum, ml-dtypes, grpcio, google-pasta, gast, astunparse, absl-py, tensorboard, keras, tensorflow\n",
      "Successfully installed absl-py-2.2.2 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google-pasta-0.2.0 grpcio-1.71.0 keras-3.9.2 libclang-18.1.1 ml-dtypes-0.5.1 namex-0.0.9 opt-einsum-3.4.0 optree-0.15.0 tensorboard-2.19.0 tensorboard-data-server-0.7.2 tensorflow-2.19.0 termcolor-3.0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: The script tensorboard.exe is installed in 'C:\\Users\\91808\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n",
      "  WARNING: The scripts import_pb_to_tensorboard.exe, saved_model_cli.exe, tensorboard.exe, tf_upgrade_v2.exe, tflite_convert.exe and toco.exe are installed in 'C:\\Users\\91808\\AppData\\Roaming\\Python\\Python312\\Scripts' which is not on PATH.\n",
      "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4eca7826-4932-4a78-bf61-e2806f394a91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91808\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.2919 - loss: 2.5504 - val_accuracy: 0.6856 - val_loss: 1.1547\n",
      "Epoch 2/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7024 - loss: 1.0380 - val_accuracy: 0.7731 - val_loss: 0.8443\n",
      "Epoch 3/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7697 - loss: 0.7868 - val_accuracy: 0.8125 - val_loss: 0.6990\n",
      "Epoch 4/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8081 - loss: 0.6526 - val_accuracy: 0.8306 - val_loss: 0.6079\n",
      "Epoch 5/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8308 - loss: 0.5724 - val_accuracy: 0.8494 - val_loss: 0.5389\n",
      "Epoch 6/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 0.4914 - val_accuracy: 0.8631 - val_loss: 0.4932\n",
      "Epoch 7/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8742 - loss: 0.4331 - val_accuracy: 0.8806 - val_loss: 0.4542\n",
      "Epoch 8/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.4016 - val_accuracy: 0.8869 - val_loss: 0.4239\n",
      "Epoch 9/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8951 - loss: 0.3633 - val_accuracy: 0.8925 - val_loss: 0.3924\n",
      "Epoch 10/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9036 - loss: 0.3352 - val_accuracy: 0.8969 - val_loss: 0.3760\n",
      "Epoch 11/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9082 - loss: 0.3151 - val_accuracy: 0.9025 - val_loss: 0.3411\n",
      "Epoch 12/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9115 - loss: 0.2945 - val_accuracy: 0.9081 - val_loss: 0.3315\n",
      "Epoch 13/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9206 - loss: 0.2745 - val_accuracy: 0.9100 - val_loss: 0.3204\n",
      "Epoch 14/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9224 - loss: 0.2667 - val_accuracy: 0.9125 - val_loss: 0.3108\n",
      "Epoch 15/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9243 - loss: 0.2498 - val_accuracy: 0.9119 - val_loss: 0.3009\n",
      "Epoch 16/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2322 - val_accuracy: 0.9181 - val_loss: 0.2799\n",
      "Epoch 17/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.2201 - val_accuracy: 0.9087 - val_loss: 0.2966\n",
      "Epoch 18/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9314 - loss: 0.2179 - val_accuracy: 0.9175 - val_loss: 0.2670\n",
      "Epoch 19/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9391 - loss: 0.2023 - val_accuracy: 0.9212 - val_loss: 0.2671\n",
      "Epoch 20/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.9403 - loss: 0.1916 - val_accuracy: 0.9175 - val_loss: 0.2585\n",
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9150 - loss: 0.2463\n",
      "\n",
      "Test Accuracy: 0.9183\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Step 1: Build a basic ANN model\n",
    "def create_base_model():\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(len(np.unique(y_train)), activation='softmax')  # one output per class\n",
    "    ])\n",
    "    \n",
    "    # Compile the model\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 2: Train the model\n",
    "model = create_base_model()\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_split=0.1, verbose=1)\n",
    "\n",
    "# Step 3: Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest Accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eaf86523-67d5-490e-bf9b-2c1968d185b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.98      0.94      0.96       158\n",
      "           B       0.89      0.82      0.86       153\n",
      "           C       0.94      0.94      0.94       147\n",
      "           D       0.94      0.91      0.92       161\n",
      "           E       0.87      0.92      0.89       154\n",
      "           F       0.94      0.88      0.91       155\n",
      "           G       0.86      0.94      0.90       155\n",
      "           H       0.86      0.85      0.85       147\n",
      "           I       0.96      0.87      0.92       151\n",
      "           J       0.91      0.92      0.91       149\n",
      "           K       0.91      0.92      0.91       148\n",
      "           L       0.92      0.93      0.92       152\n",
      "           M       0.99      0.93      0.96       158\n",
      "           N       0.90      0.94      0.92       157\n",
      "           O       0.95      0.89      0.92       150\n",
      "           P       0.95      0.95      0.95       161\n",
      "           Q       0.94      0.95      0.95       157\n",
      "           R       0.81      0.88      0.84       151\n",
      "           S       0.88      0.94      0.91       150\n",
      "           T       0.92      0.90      0.91       159\n",
      "           U       0.93      0.97      0.95       163\n",
      "           V       0.91      0.93      0.92       153\n",
      "           W       0.93      1.00      0.96       150\n",
      "           X       0.88      0.89      0.89       157\n",
      "           Y       0.95      0.94      0.95       157\n",
      "           Z       1.00      0.91      0.95       147\n",
      "\n",
      "    accuracy                           0.92      4000\n",
      "   macro avg       0.92      0.92      0.92      4000\n",
      "weighted avg       0.92      0.92      0.92      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Classification report\n",
    "y_pred = np.argmax(model.predict(X_test), axis=1)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a0999ec9-08b7-4dbd-92eb-a11e9946c527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting scikeras[tensorflow]\n",
      "  Downloading scikeras-0.13.0-py3-none-any.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: keras>=3.2.0 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from scikeras[tensorflow]) (3.9.2)\n",
      "Requirement already satisfied: scikit-learn>=1.4.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikeras[tensorflow]) (1.5.1)\n",
      "Requirement already satisfied: tensorflow>=2.16.1 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from scikeras[tensorflow]) (2.19.0)\n",
      "Requirement already satisfied: absl-py in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (1.26.4)\n",
      "Requirement already satisfied: rich in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (13.7.1)\n",
      "Requirement already satisfied: namex in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.0.9)\n",
      "Requirement already satisfied: h5py in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (3.11.0)\n",
      "Requirement already satisfied: optree in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.15.0)\n",
      "Requirement already satisfied: ml-dtypes in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (0.5.1)\n",
      "Requirement already satisfied: packaging in c:\\programdata\\anaconda3\\lib\\site-packages (from keras>=3.2.0->scikeras[tensorflow]) (24.1)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn>=1.4.2->scikeras[tensorflow]) (3.5.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (25.2.10)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.4.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.32.3)\n",
      "Requirement already satisfied: setuptools in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (3.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (1.71.0)\n",
      "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorflow>=2.16.1->scikeras[tensorflow]) (2.19.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from astunparse>=1.6.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.44.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2025.1.31)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\91808\\appdata\\roaming\\python\\python312\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (3.0.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from rich->keras>=3.2.0->scikeras[tensorflow]) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->scikeras[tensorflow]) (0.1.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow>=2.16.1->scikeras[tensorflow]) (2.1.3)\n",
      "Downloading scikeras-0.13.0-py3-none-any.whl (26 kB)\n",
      "Installing collected packages: scikeras\n",
      "Successfully installed scikeras-0.13.0\n"
     ]
    }
   ],
   "source": [
    "!pip install scikeras[tensorflow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff08e8d3-e6f4-4a88-a6d7-4462bba0c7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 5 candidates, totalling 15 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91808\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.9031\n",
      "Best Params: {'model__optimizer': 'adam', 'model__learning_rate': 0.001, 'model__hidden_layer_2': 32, 'model__hidden_layer_1': 64, 'model__activation': 'relu', 'epochs': 20, 'batch_size': 32}\n"
     ]
    }
   ],
   "source": [
    "from scikeras.wrappers import KerasClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "# Step 1: Define model-building function\n",
    "def create_model(hidden_layer_1=64, hidden_layer_2=32, activation='relu', optimizer='adam', learning_rate=0.001):\n",
    "    if optimizer == 'adam':\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "    else:\n",
    "        opt = RMSprop(learning_rate=learning_rate)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(hidden_layer_1, activation=activation, input_shape=(X_train.shape[1],)))\n",
    "    model.add(Dense(hidden_layer_2, activation=activation))\n",
    "    model.add(Dense(len(np.unique(y_train)), activation='softmax'))\n",
    "    \n",
    "    model.compile(optimizer=opt, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Step 2: Wrap with scikeras KerasClassifier\n",
    "model = KerasClassifier(\n",
    "    model=create_model,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "# Step 3: Define hyperparameter grid (use model__ prefix for custom params)\n",
    "param_grid = {\n",
    "    'model__hidden_layer_1': [64, 128],\n",
    "    'model__hidden_layer_2': [32, 64],\n",
    "    'model__activation': ['relu', 'tanh'],\n",
    "    'model__optimizer': ['adam', 'rmsprop'],\n",
    "    'model__learning_rate': [0.001, 0.0005],\n",
    "    'batch_size': [32, 64],\n",
    "    'epochs': [10, 20]\n",
    "}\n",
    "\n",
    "# Step 4: Randomized search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=model,\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=5,\n",
    "    cv=3,\n",
    "    verbose=2,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Step 5: Fit the model\n",
    "random_search_result = random_search.fit(X_train, y_train)\n",
    "\n",
    "# Step 6: Print best result\n",
    "print(\"Best Score: {:.4f}\".format(random_search_result.best_score_))\n",
    "print(\"Best Params:\", random_search_result.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5fbb80d2-8c14-4a56-8c9c-b79dd91ce2d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91808\\AppData\\Roaming\\Python\\Python312\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m125/125\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "📊 Classification Report – Default Model\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           A       0.94      0.92      0.93       158\n",
      "           B       0.83      0.88      0.85       153\n",
      "           C       0.92      0.98      0.95       147\n",
      "           D       0.85      0.91      0.88       161\n",
      "           E       0.84      0.87      0.86       154\n",
      "           F       0.86      0.83      0.84       155\n",
      "           G       0.90      0.83      0.86       155\n",
      "           H       0.82      0.79      0.80       147\n",
      "           I       0.94      0.84      0.89       151\n",
      "           J       0.91      0.88      0.89       149\n",
      "           K       0.92      0.84      0.88       148\n",
      "           L       0.89      0.88      0.89       152\n",
      "           M       0.95      0.93      0.94       158\n",
      "           N       0.88      0.91      0.90       157\n",
      "           O       0.89      0.91      0.90       150\n",
      "           P       0.90      0.93      0.92       161\n",
      "           Q       0.89      0.96      0.92       157\n",
      "           R       0.85      0.85      0.85       151\n",
      "           S       0.83      0.89      0.86       150\n",
      "           T       0.92      0.87      0.89       159\n",
      "           U       0.96      0.95      0.95       163\n",
      "           V       0.89      0.92      0.90       153\n",
      "           W       0.97      0.94      0.95       150\n",
      "           X       0.80      0.89      0.84       157\n",
      "           Y       0.90      0.89      0.90       157\n",
      "           Z       0.97      0.88      0.93       147\n",
      "\n",
      "    accuracy                           0.89      4000\n",
      "   macro avg       0.89      0.89      0.89      4000\n",
      "weighted avg       0.89      0.89      0.89      4000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and train a default model (same as earlier)\n",
    "default_model = create_model()\n",
    "default_model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0, validation_split=0.1)\n",
    "\n",
    "# Predict and evaluate\n",
    "y_pred_default = np.argmax(default_model.predict(X_test), axis=1)\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(\"📊 Classification Report – Default Model\")\n",
    "print(classification_report(y_test, y_pred_default, target_names=label_encoder.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b02d27-277a-4b92-8045-38fd47e35ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
